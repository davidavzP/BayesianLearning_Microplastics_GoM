{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ddbf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "import timeit\n",
    "import math\n",
    "import time\n",
    "import sparse\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "from scipy import interpolate\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "from glob import glob\n",
    "from os import path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd80b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-97.98001098632812,\n",
       " -76.45999145507812,\n",
       " 18.140000343322754,\n",
       " 31.899998664855957,\n",
       " 345,\n",
       " 539,\n",
       " 0.03997802734375,\n",
       " 0.03999900817871094)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputDir = 'data/posterior_computation_data/'\n",
    "gom_masks = xr.open_dataset(outputDir + 'domain_cell_masks.nc')\n",
    "\n",
    "# GLOBAL CONSTANTS\n",
    "MIN_LON = np.min(gom_masks['lon'].values)\n",
    "MAX_LON = np.max(gom_masks['lon'].values)\n",
    "MIN_LAT = np.min(gom_masks['lat'].values)\n",
    "MAX_LAT = np.max(gom_masks['lat'].values)\n",
    "\n",
    "#domain width and height (cell counts)\n",
    "LAT_SIZE = gom_masks.dims['lat']\n",
    "LON_SIZE = gom_masks.dims['lon']\n",
    "\n",
    "#cell size\n",
    "D_LON = gom_masks[\"lon\"][1].values - gom_masks[\"lon\"][0].values\n",
    "D_LAT = gom_masks[\"lat\"][1].values - gom_masks[\"lat\"][0].values\n",
    "\n",
    "BIN_CELL_LATS = gom_masks.bin_cell_lats.values\n",
    "BIN_CELL_LONS = gom_masks.bin_cell_lons.values\n",
    "\n",
    "MIN_LON, MAX_LON, MIN_LAT, MAX_LAT,LAT_SIZE,LON_SIZE, D_LON,D_LAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6768151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111347.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(gom_masks.oceanmask.values[np.where(gom_masks.source_cells_map > 0.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641a0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save domain_cell_tree\n",
    "fileObj = open(outputDir + 'output_dict.obj', 'rb')\n",
    "output = pickle.load(fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab92fcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 114024, 30, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cell_beaching = output['n_cell_beaching']\n",
    "n_cell_source = output['n_cell_source']\n",
    "n_window_beaching = output['n_window_beaching'] \n",
    "n_window_source = output['n_window_source']\n",
    "\n",
    "particle_count = output['particle_count']\n",
    "\n",
    "beaching_cells = output['beaching_cells'] \n",
    "beaching_cell_tree = output['beaching_cell_tree']\n",
    "\n",
    "source_cell_mask = output['source_cell_mask']\n",
    "source_cells = output['source_cells']\n",
    "source_cell_tree = output['source_cell_tree']\n",
    "\n",
    "beaching_windows = output['beaching_windows']\n",
    "source_windows = output['source_windows']\n",
    "d = output['d']\n",
    "beaching_ym_mat = output['beaching_ym_mat']\n",
    "source_ym_mat = output['source_ym_mat']\n",
    "\n",
    "n_cell_beaching,n_cell_source,n_window_beaching, n_window_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e97a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1479it [00:18, 81.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Mexico Border\n",
    "mexico_border = ((gom_masks.coastalmask + ((gom_masks['lat'] <= 25.57) & (gom_masks['lon'] < -85.5))) == 2)\n",
    "\n",
    "# Caribbean/Island Border\n",
    "ci_border = ((gom_masks.coastalmask + ((gom_masks['lat'] <= 27.5) & (gom_masks['lon'] >= -85.5) & \n",
    "                                      ~((gom_masks['lat'] <= 27.5) & (gom_masks['lon'] >= -85.5) & \n",
    "                                        (gom_masks['lat'] >= 24.2) & (gom_masks['lon'] <= -79.5)))) == 2)\n",
    "\n",
    "\n",
    "usa_border = (gom_masks.coastalmask  - (mexico_border + ci_border) )\n",
    "\n",
    "all_gom_regions = np.array(['Caribbean','Mexico','Texas', 'Louisiana', 'Mississippi','Alabama', 'Florida'])\n",
    "usa_lats_idx, usa_lons_idx = np.where(usa_border == 1.0)\n",
    "\n",
    "usa_lats = usa_border['lat'].values[usa_lats_idx]\n",
    "usa_lons = usa_border['lon'].values[usa_lons_idx]\n",
    "\n",
    "usa_state_idx = np.ones(len(usa_lats))\n",
    "\n",
    "for i1,(lon_,lat_) in tqdm(enumerate(zip(usa_lons,usa_lats))):\n",
    "    temp_dist = np.inf\n",
    "    shpfilename = shpreader.natural_earth(resolution='110m',\n",
    "                                      category='cultural',\n",
    "                                      name='admin_1_states_provinces')\n",
    "    reader = shpreader.Reader(shpfilename)\n",
    "    states = reader.records()\n",
    "    for state in states:\n",
    "        geom = state.geometry\n",
    "        state_name = str(state.attributes['name_en']).replace('\\x00','')\n",
    "        \n",
    "        if state_name in all_gom_regions:\n",
    "            dist = geom.distance(Point(lon_, lat_))\n",
    "            if dist < temp_dist:\n",
    "                idx_state = np.where(all_gom_regions == state_name)[0]\n",
    "                temp_dist = dist\n",
    "    usa_state_idx[i1] += idx_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d4009",
   "metadata": {},
   "source": [
    "Assign Source Region Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5813ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ids = np.zeros((LAT_SIZE, LON_SIZE))\n",
    "state_ids[usa_lats_idx, usa_lons_idx] = usa_state_idx\n",
    "\n",
    "mbv = np.array(mexico_border.values, dtype = np.float32)\n",
    "mbv[np.where(mexico_border == 1.0)] = 2.0\n",
    "\n",
    "all_coastal_regions = (state_ids + mbv + ci_border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820606f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gom_regions_o = ['LaTex Shelf', 'nWFS Shelf', 'sWFS Shelf', 'CCarribean', 'Campeche Bay', 'weGOM', 'eeGOM']\n",
    "o_regions = np.zeros((len(all_gom_regions_o), LAT_SIZE, LON_SIZE))\n",
    "\n",
    "last_region_idx = np.max(all_coastal_regions).values\n",
    "gom_cutout = (gom_masks.landmask + gom_masks.coastalmask).astype('bool')\n",
    "\n",
    "# LaTex Shelf\n",
    "latex_self = ((~(gom_cutout) & (gom_masks.lon < -90.0) & (gom_masks.lat > 27.0)) \n",
    "              & ~(~(gom_cutout)& (gom_masks.depth > 500) & (gom_masks.lon < -90.0) & (gom_masks.lat > 27.0)))\n",
    "o_regions[0, :, :] += latex_self\n",
    "\n",
    "# nWFS Shelf\n",
    "nWFS_shelf = (~(gom_cutout) & (gom_masks.lon >= -90.0) & (gom_masks.lat > 29.0) & (gom_masks.lon < -82.5))\n",
    "o_regions[1, :, :] += nWFS_shelf\n",
    "\n",
    "# sWFS Shelf\n",
    "sWFS_shelf_1 = (~(~(gom_cutout) & (gom_masks.depth >= 200) & (gom_masks.lon > -85.5) & (gom_masks.lon < -81.0) & (gom_masks.lat <= 29.0) & (gom_masks.lat > 24.0)))\n",
    "sWFS_shelf = sWFS_shelf_1 & ((~(gom_cutout) & (gom_masks.lon > -85.5) & (gom_masks.lon < -81.0) & (gom_masks.lat <= 29.0) & (gom_masks.lat > 24.0)))\n",
    "o_regions[2, :, :] += sWFS_shelf\n",
    "\n",
    "# Carribean\n",
    "carribean = (~(gom_cutout) & (gom_masks.lon > -85.5) & (np.power((gom_masks.lat - 20.0) / .9, 2) + (np.power((gom_masks.lon + 80.) / 1.2, 2)) < 22) )\n",
    "o_regions[3, :, :] += carribean\n",
    "\n",
    "# Campeche Bay\n",
    "campeche_bay = (~(gom_cutout)  & (np.power((gom_masks.lat - 17.0) , 2) + (np.power((gom_masks.lon + 95.) / 1.5, 2)) < 22))\n",
    "o_regions[4, :, :] += campeche_bay\n",
    "\n",
    "# weGOM\n",
    "weGOM = (((gom_masks.lat) + 2.*(gom_masks.lon + 90) < 27) & ((gom_masks.lat) -1.5*(gom_masks.lon + 86) > 24) \n",
    "         & ~(gom_cutout) \n",
    "         & ~((~(gom_cutout)  & (np.power((gom_masks.lat - 17.0) , 2) + (np.power((gom_masks.lon + 95.) / 1.5, 2)) < 22)))\n",
    "         & ~((~(gom_cutout) & (gom_masks.lon < -90.0) & (gom_masks.lat > 27.0)) & ~(~(gom_cutout)& (gom_masks.depth > 500) & (gom_masks.lon < -90.0) & (gom_masks.lat > 27.0))))\n",
    "o_regions[5, :, :] += weGOM\n",
    "\n",
    "# eeGOM\n",
    "eeGOM = (~(((gom_masks.lat) + 2.*(gom_masks.lon + 90) < 27) & ((gom_masks.lat) -1.5*(gom_masks.lon + 86) > 24)) & ~(gom_cutout)\n",
    "         & ~(~(gom_cutout) & (gom_masks.lon > -85.5) & (np.power((gom_masks.lat - 20.0) / .9, 2) + (np.power((gom_masks.lon + 80.) / 1.2, 2)) < 22) )\n",
    "         & ~ (sWFS_shelf_1 & ((~(gom_cutout) & (gom_masks.lon > -85.5) & (gom_masks.lon < -81.0) & (gom_masks.lat <= 29.0) & (gom_masks.lat > 24.0))))\n",
    "         & ~(~(gom_cutout) & (gom_masks.lon >= -90.0) & (gom_masks.lat > 29.0) & (gom_masks.lon < -82.5))\n",
    "         & ~((~(gom_cutout) & (gom_masks.lon < -90.0) & (gom_masks.lat > 27.0)) & ~(~(gom_cutout)& (gom_masks.depth > 500) & (gom_masks.lon < -90.0) & (gom_masks.lat > 27.0))))\n",
    "o_regions[6, :, :] += eeGOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458bee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_names = all_gom_regions\n",
    "coastal_maps = all_coastal_regions\n",
    "\n",
    "ocean_names = all_gom_regions_o\n",
    "ocean_maps = o_regions\n",
    "\n",
    "ocean_names_len = len(coastal_names)\n",
    "ocean_region_ids = np.arange(ocean_names_len+1, 2*ocean_names_len + 1 )[:, None, None]\n",
    "\n",
    "argm_temp = (ocean_maps  * ocean_region_ids)\n",
    "ocean_regions_groups_map = np.sum(argm_temp, axis = 0)\n",
    "\n",
    "##########################\n",
    "group_source_region_map   = coastal_maps+ocean_regions_groups_map \n",
    "gom_masks = gom_masks.assign(group_source_region_map  = (('lat', 'lon'), group_source_region_map.values ))\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f1e1d",
   "metadata": {},
   "source": [
    "Assign Beaching Region Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03460fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "beaching_cell_mask = (gom_masks.nurdlecount > 0.0)\n",
    "group_beaching_region_map = (group_source_region_map * beaching_cell_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf997e8f",
   "metadata": {},
   "source": [
    "Assign Posterior Aggregation Labels for groups and periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56bf5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for Cell and Window Level Aggregation\n",
    "source_cell_groups = np.tile(np.arange(n_cell_source), (d+1))\n",
    "beaching_cell_groups = np.tile(np.arange(n_cell_beaching), n_window_beaching)\n",
    "beaching_window_groups = np.repeat(np.arange(n_window_beaching), n_cell_beaching)\n",
    "\n",
    "# Used for Region and Month Level Aggregation\n",
    "group_source_region = group_source_region_map.values[source_cell_mask]\n",
    "assert(len(np.where(group_source_region == 0.0)[0]) == 0.0)\n",
    "\n",
    "group_beaching_region = group_beaching_region_map.values[beaching_cell_mask]\n",
    "assert(len(np.where(group_beaching_region == 0.0)[0]) == 0.0)\n",
    "\n",
    "group_beaching_month = np.where(beaching_ym_mat >= 0.0)[1] + 1\n",
    "\n",
    "group_source_region_names = np.concatenate([coastal_names, ocean_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fa0a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "output = {}\n",
    "output['source_cell_groups'] = source_cell_groups\n",
    "output['beaching_cell_groups'] = beaching_cell_groups\n",
    "output['beaching_window_groups'] = beaching_window_groups\n",
    "\n",
    "output['group_source_region'] = group_source_region\n",
    "output['group_beaching_region'] = group_beaching_region\n",
    "output['group_beaching_month'] = group_beaching_month\n",
    "output['group_source_region_names'] = group_source_region_names\n",
    "# Save domain_cell_tree\n",
    "fileObj_output = open(outputDir + 'agg_dict.obj', 'wb')\n",
    "pickle.dump(output,fileObj_output)\n",
    "fileObj_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0e034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gom_masks.to_netcdf(outputDir +'domain_cell_masks_w_regions.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9582d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove zarr\n",
    "# import shutil\n",
    "# shutil.rmtree(outputDir + '/source_agg_n_post.zarr', ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 py3_parcels",
   "language": "python",
   "name": "py3_parcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
